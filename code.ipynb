{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe4ed6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194216a4",
   "metadata": {},
   "source": [
    "# Pair Sampling Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ce27ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairFERDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.dataset = ImageFolder(root=root_dir)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((112, 112)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "        self.class_to_images = {i: [] for i in range(len(self.dataset.classes))}\n",
    "        for idx, (_, label) in enumerate(self.dataset.samples):\n",
    "            self.class_to_images[label].append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1, label = self.dataset[idx]\n",
    "        idx2 = random.choice(self.class_to_images[label])\n",
    "        img2, _ = self.dataset[idx2]\n",
    "        return self.transform(img1), self.transform(img2), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae1113",
   "metadata": {},
   "source": [
    "# Model Componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f15c2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, output_dim=64):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])  # output: (B, 512, 1, 1)\n",
    "        self.projector = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)           # (B, 512, 1, 1)\n",
    "        x = x.view(x.size(0), -1)               # (B, 512)\n",
    "        return self.projector(x)                # (B, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04b7b5",
   "metadata": {},
   "source": [
    "# Mutual Information Estimator (MINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "488d1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, e, i):\n",
    "        return self.net(torch.cat([e, i], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660fccf",
   "metadata": {},
   "source": [
    "# Discriminator for Adversarial MI Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "534a478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator for Adversarial MI Minimization\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, e, i):\n",
    "        return self.net(torch.cat([e, i], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d2789",
   "metadata": {},
   "source": [
    "# Mutual Information Estimation (MINE Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc92d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_mi(mine, x, y):\n",
    "    joint = mine(x, y).mean()\n",
    "    y_perm = y[torch.randperm(y.size(0))]\n",
    "    marginal = torch.clamp(torch.exp(mine(x, y_perm)).mean(), min=1e-8, max=1e8)\n",
    "    return joint - torch.log(marginal + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b58f04",
   "metadata": {},
   "source": [
    "# Classifier (Final FER model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "575f49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=64, num_classes=7):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa0a7c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72b9a3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture Demo:\n",
      "Input shape: torch.Size([4, 3, 112, 112])\n",
      "Expression embedding shape: torch.Size([4, 64])\n",
      "Identity embedding shape: torch.Size([4, 64])\n",
      "MI score shape: torch.Size([4, 1])\n",
      "Discriminator score shape: torch.Size([4, 1])\n",
      "Classification output shape: torch.Size([4, 7])\n",
      "\n",
      "Model summary:\n",
      "Expression Encoder parameters: 11209344\n",
      "Identity Encoder parameters: 11209344\n",
      "Statistics Network parameters: 33281\n",
      "Discriminator parameters: 33281\n",
      "Classifier parameters: 9223\n",
      "Using device: cuda\n",
      "Starting training...\n",
      "Epoch 0, Batch 0: MI Loss=0.0604, Clf Loss=1.9309\n",
      "Epoch 0, Batch 90: MI Loss=0.0569, Clf Loss=1.9881\n",
      "Epoch 0, Batch 180: MI Loss=0.0644, Clf Loss=1.9395\n",
      "Epoch 0, Batch 270: MI Loss=0.0656, Clf Loss=1.9639\n",
      "Epoch 0, Batch 360: MI Loss=0.0559, Clf Loss=1.9826\n",
      "Epoch 0, Batch 450: MI Loss=0.0710, Clf Loss=1.9705\n",
      "Epoch 0, Batch 540: MI Loss=0.0691, Clf Loss=1.9585\n",
      "Epoch 0, Batch 630: MI Loss=0.0813, Clf Loss=1.9671\n",
      "Epoch 0, Batch 720: MI Loss=0.0618, Clf Loss=1.9611\n",
      "Epoch 0, Batch 810: MI Loss=0.0667, Clf Loss=1.9359\n",
      "Epoch 0 Complete: Avg MI Loss=0.0665, Avg Clf Loss=1.9638\n",
      "Epoch 1, Batch 0: MI Loss=0.0689, Clf Loss=1.9693\n",
      "Epoch 1, Batch 90: MI Loss=0.0913, Clf Loss=1.9669\n",
      "Epoch 1, Batch 180: MI Loss=0.0811, Clf Loss=1.9640\n",
      "Epoch 1, Batch 270: MI Loss=0.0843, Clf Loss=1.9424\n",
      "Epoch 1, Batch 360: MI Loss=0.1018, Clf Loss=1.9507\n",
      "Epoch 1, Batch 450: MI Loss=0.0987, Clf Loss=2.0246\n",
      "Epoch 1, Batch 540: MI Loss=0.1118, Clf Loss=1.9166\n",
      "Epoch 1, Batch 630: MI Loss=0.1268, Clf Loss=2.0008\n",
      "Epoch 1, Batch 720: MI Loss=0.1286, Clf Loss=1.9531\n",
      "Epoch 1, Batch 810: MI Loss=0.1701, Clf Loss=1.8873\n",
      "Epoch 1 Complete: Avg MI Loss=0.1078, Avg Clf Loss=1.9550\n",
      "Epoch 2, Batch 0: MI Loss=0.1719, Clf Loss=1.9838\n",
      "Epoch 2, Batch 90: MI Loss=0.2197, Clf Loss=1.9692\n",
      "Epoch 2, Batch 180: MI Loss=0.2039, Clf Loss=1.9588\n",
      "Epoch 2, Batch 270: MI Loss=0.2295, Clf Loss=1.9380\n",
      "Epoch 2, Batch 360: MI Loss=0.2212, Clf Loss=1.9602\n",
      "Epoch 2, Batch 450: MI Loss=0.2913, Clf Loss=1.9454\n",
      "Epoch 2, Batch 540: MI Loss=0.2568, Clf Loss=1.9013\n",
      "Epoch 2, Batch 630: MI Loss=0.2936, Clf Loss=1.9167\n",
      "Epoch 2, Batch 720: MI Loss=0.2849, Clf Loss=1.9975\n",
      "Epoch 2, Batch 810: MI Loss=0.2628, Clf Loss=1.8657\n",
      "Epoch 2 Complete: Avg MI Loss=0.2465, Avg Clf Loss=1.9459\n",
      "Epoch 3, Batch 0: MI Loss=0.3029, Clf Loss=1.9728\n",
      "Epoch 3, Batch 90: MI Loss=0.2965, Clf Loss=1.9735\n",
      "Epoch 3, Batch 180: MI Loss=0.2967, Clf Loss=1.8568\n",
      "Epoch 3, Batch 270: MI Loss=0.2840, Clf Loss=1.9611\n",
      "Epoch 3, Batch 360: MI Loss=0.2571, Clf Loss=1.9332\n",
      "Epoch 3, Batch 450: MI Loss=0.3073, Clf Loss=1.9255\n",
      "Epoch 3, Batch 540: MI Loss=0.3181, Clf Loss=1.9213\n",
      "Epoch 3, Batch 630: MI Loss=0.3237, Clf Loss=1.9641\n",
      "Epoch 3, Batch 720: MI Loss=0.2858, Clf Loss=1.8699\n",
      "Epoch 3, Batch 810: MI Loss=0.2830, Clf Loss=1.8919\n",
      "Epoch 3 Complete: Avg MI Loss=0.2924, Avg Clf Loss=1.9267\n",
      "Epoch 4, Batch 0: MI Loss=0.3053, Clf Loss=1.9335\n",
      "Epoch 4, Batch 90: MI Loss=0.2766, Clf Loss=1.8943\n",
      "Epoch 4, Batch 180: MI Loss=0.2836, Clf Loss=1.8758\n",
      "Epoch 4, Batch 270: MI Loss=0.2406, Clf Loss=1.8672\n",
      "Epoch 4, Batch 360: MI Loss=0.3301, Clf Loss=1.8786\n",
      "Epoch 4, Batch 450: MI Loss=0.2755, Clf Loss=1.8664\n",
      "Epoch 4, Batch 540: MI Loss=0.2761, Clf Loss=1.9119\n",
      "Epoch 4, Batch 630: MI Loss=0.2810, Clf Loss=1.9043\n",
      "Epoch 4, Batch 720: MI Loss=0.2929, Clf Loss=1.9355\n",
      "Epoch 4, Batch 810: MI Loss=0.2752, Clf Loss=1.8787\n",
      "Epoch 4 Complete: Avg MI Loss=0.2923, Avg Clf Loss=1.9090\n",
      "Epoch 5, Batch 0: MI Loss=0.3059, Clf Loss=1.8447\n",
      "Epoch 5, Batch 90: MI Loss=0.3288, Clf Loss=1.9212\n",
      "Epoch 5, Batch 180: MI Loss=0.3084, Clf Loss=1.8282\n",
      "Epoch 5, Batch 270: MI Loss=0.2561, Clf Loss=1.9398\n",
      "Epoch 5, Batch 360: MI Loss=0.3175, Clf Loss=1.9305\n",
      "Epoch 5, Batch 450: MI Loss=0.3025, Clf Loss=1.8783\n",
      "Epoch 5, Batch 540: MI Loss=0.2670, Clf Loss=1.9169\n",
      "Epoch 5, Batch 630: MI Loss=0.3197, Clf Loss=1.8839\n",
      "Epoch 5, Batch 720: MI Loss=0.2895, Clf Loss=1.8996\n",
      "Epoch 5, Batch 810: MI Loss=0.3215, Clf Loss=1.8182\n",
      "Epoch 5 Complete: Avg MI Loss=0.2928, Avg Clf Loss=1.8960\n",
      "Epoch 6, Batch 0: MI Loss=0.2858, Clf Loss=1.8488\n",
      "Epoch 6, Batch 90: MI Loss=0.3118, Clf Loss=1.9218\n",
      "Epoch 6, Batch 180: MI Loss=0.2799, Clf Loss=1.8447\n",
      "Epoch 6, Batch 270: MI Loss=0.2872, Clf Loss=1.9182\n",
      "Epoch 6, Batch 360: MI Loss=0.3199, Clf Loss=1.9630\n",
      "Epoch 6, Batch 450: MI Loss=0.3308, Clf Loss=1.8955\n",
      "Epoch 6, Batch 540: MI Loss=0.2891, Clf Loss=1.8869\n",
      "Epoch 6, Batch 630: MI Loss=0.2763, Clf Loss=1.9003\n",
      "Epoch 6, Batch 720: MI Loss=0.3098, Clf Loss=1.8861\n",
      "Epoch 6, Batch 810: MI Loss=0.2801, Clf Loss=1.8802\n",
      "Epoch 6 Complete: Avg MI Loss=0.3021, Avg Clf Loss=1.8852\n",
      "Epoch 7, Batch 0: MI Loss=0.2371, Clf Loss=1.9475\n",
      "Epoch 7, Batch 90: MI Loss=0.3439, Clf Loss=1.8781\n",
      "Epoch 7, Batch 180: MI Loss=0.2683, Clf Loss=1.9278\n",
      "Epoch 7, Batch 270: MI Loss=0.2698, Clf Loss=1.9094\n",
      "Epoch 7, Batch 360: MI Loss=0.2965, Clf Loss=1.9345\n",
      "Epoch 7, Batch 450: MI Loss=0.3007, Clf Loss=1.8673\n",
      "Epoch 7, Batch 540: MI Loss=0.3273, Clf Loss=1.8220\n",
      "Epoch 7, Batch 630: MI Loss=0.3247, Clf Loss=1.8412\n",
      "Epoch 7, Batch 720: MI Loss=0.3001, Clf Loss=1.8419\n",
      "Epoch 7, Batch 810: MI Loss=0.3514, Clf Loss=1.9469\n",
      "Epoch 7 Complete: Avg MI Loss=0.3084, Avg Clf Loss=1.8736\n",
      "Epoch 8, Batch 0: MI Loss=0.2893, Clf Loss=1.7847\n",
      "Epoch 8, Batch 90: MI Loss=0.2995, Clf Loss=1.8383\n",
      "Epoch 8, Batch 180: MI Loss=0.2951, Clf Loss=1.8186\n",
      "Epoch 8, Batch 270: MI Loss=0.3500, Clf Loss=1.8770\n",
      "Epoch 8, Batch 360: MI Loss=0.3120, Clf Loss=1.8414\n",
      "Epoch 8, Batch 450: MI Loss=0.3025, Clf Loss=1.8673\n",
      "Epoch 8, Batch 540: MI Loss=0.3403, Clf Loss=1.8540\n",
      "Epoch 8, Batch 630: MI Loss=0.2615, Clf Loss=1.8921\n",
      "Epoch 8, Batch 720: MI Loss=0.3210, Clf Loss=1.9140\n",
      "Epoch 8, Batch 810: MI Loss=0.3105, Clf Loss=1.8942\n",
      "Epoch 8 Complete: Avg MI Loss=0.3101, Avg Clf Loss=1.8563\n",
      "Epoch 9, Batch 0: MI Loss=0.3097, Clf Loss=1.8923\n",
      "Epoch 9, Batch 90: MI Loss=0.3166, Clf Loss=1.7825\n",
      "Epoch 9, Batch 180: MI Loss=0.3146, Clf Loss=1.8604\n",
      "Epoch 9, Batch 270: MI Loss=0.3265, Clf Loss=1.8405\n",
      "Epoch 9, Batch 360: MI Loss=0.3170, Clf Loss=1.8669\n",
      "Epoch 9, Batch 450: MI Loss=0.3130, Clf Loss=1.8866\n",
      "Epoch 9, Batch 540: MI Loss=0.3058, Clf Loss=1.8320\n",
      "Epoch 9, Batch 630: MI Loss=0.3502, Clf Loss=1.8341\n",
      "Epoch 9, Batch 720: MI Loss=0.3021, Clf Loss=1.7855\n",
      "Epoch 9, Batch 810: MI Loss=0.3221, Clf Loss=1.8212\n",
      "Epoch 9 Complete: Avg MI Loss=0.3077, Avg Clf Loss=1.8429\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create dummy dataset for demonstration (replace with your actual dataset path)\n",
    "    try:\n",
    "        dataset = PairFERDataset(\"train\")\n",
    "        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    except:\n",
    "        print(\"Dataset not found. Please ensure 'train' directory exists with proper structure.\")\n",
    "        return\n",
    "\n",
    "    # Models\n",
    "    E_exp = Encoder().to(device)\n",
    "    E_id = Encoder().to(device)\n",
    "    stat_net = StatisticsNetwork(64).to(device)\n",
    "    disc = Discriminator(64).to(device)\n",
    "    clf = ExpressionClassifier().to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    opt_all = optim.Adam(list(E_exp.parameters()) + list(E_id.parameters()) +\n",
    "                         list(stat_net.parameters()) + list(disc.parameters()), lr=1e-6)\n",
    "    opt_clf = optim.Adam(clf.parameters(), lr=1e-6)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        epoch_loss_exp = 0\n",
    "        epoch_loss_clf = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (m, n, label) in enumerate(dataloader):\n",
    "            m, n, label = m.to(device), n.to(device), label.to(device)\n",
    "\n",
    "            # Convert grayscale to RGB if needed\n",
    "            if m.shape[1] == 1:\n",
    "                m = m.repeat(1, 3, 1, 1)\n",
    "            if n.shape[1] == 1:\n",
    "                n = n.repeat(1, 3, 1, 1)\n",
    "\n",
    "            # Encode images\n",
    "            EM, EN = E_exp(m), E_exp(n)  # Expression embeddings\n",
    "            IM, IN = E_id(m), E_id(n)    # Identity embeddings\n",
    "\n",
    "            # Expression MI maximization (we want similar expressions to have high MI)\n",
    "            # Here we estimate MI between expression embeddings of the same class\n",
    "            mi_exp = estimate_mi(stat_net, EM, EN)\n",
    "            \n",
    "            # L1 regularization to encourage similar expression embeddings for same class\n",
    "            l1 = torch.mean(torch.abs(EM - EN))\n",
    "            loss_exp = -mi_exp + 0.1 * l1\n",
    "\n",
    "            # Identity MI minimization (we want to remove identity info from expression embeddings)\n",
    "            # Create combined embeddings for identity estimation\n",
    "            TM = torch.cat([EM, IM], dim=1)\n",
    "            TN = torch.cat([EN, IN], dim=1)\n",
    "            \n",
    "            # We want to minimize MI between expression and identity embeddings\n",
    "            mi_id_exp = estimate_mi(stat_net, EM, IM)\n",
    "            mi_id_exp_n = estimate_mi(stat_net, EN, IN)\n",
    "            mi_id = mi_id_exp + mi_id_exp_n\n",
    "\n",
    "            # Adversarial loss for identity disentanglement\n",
    "            real = disc(EM, IM)\n",
    "            fake = disc(EM, IN[torch.randperm(IN.size(0))])\n",
    "            loss_adv = -torch.mean(torch.log(real + 1e-6) + torch.log(1 - fake + 1e-6))\n",
    "\n",
    "            # Total loss for encoder training\n",
    "            loss_total = loss_exp + mi_id + 0.1 * loss_adv\n",
    "\n",
    "            # Update encoders, statistics network, and discriminator\n",
    "            opt_all.zero_grad()\n",
    "            loss_total.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(list(E_exp.parameters()) + list(E_id.parameters()) + \n",
    "                                           list(stat_net.parameters()) + list(disc.parameters()), max_norm=1.0)\n",
    "            opt_all.step()\n",
    "\n",
    "            # Train classifier on expression embeddings\n",
    "            pred = clf(EM.detach())\n",
    "            loss_clf = loss_fn(pred, label)\n",
    "\n",
    "            opt_clf.zero_grad()\n",
    "            loss_clf.backward()\n",
    "            opt_clf.step()\n",
    "\n",
    "            epoch_loss_exp += loss_exp.item()\n",
    "            epoch_loss_clf += loss_clf.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            if batch_idx % 90 == 0:\n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}: MI Loss={loss_exp.item():.4f}, Clf Loss={loss_clf.item():.4f}\")\n",
    "\n",
    "        avg_loss_exp = epoch_loss_exp / num_batches\n",
    "        avg_loss_clf = epoch_loss_clf / num_batches\n",
    "        print(f\"Epoch {epoch} Complete: Avg MI Loss={avg_loss_exp:.4f}, Avg Clf Loss={avg_loss_clf:.4f}\")\n",
    "\n",
    "    print(\"Training completed!\")\n",
    "\n",
    "# Demo function to show model architecture\n",
    "def demo_model():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create models\n",
    "    E_exp = Encoder().to(device)\n",
    "    E_id = Encoder().to(device)\n",
    "    stat_net = StatisticsNetwork(64).to(device)\n",
    "    disc = Discriminator(64).to(device)\n",
    "    clf = ExpressionClassifier().to(device)\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = torch.randn(4, 3, 112, 112).to(device)\n",
    "    \n",
    "    print(\"Model Architecture Demo:\")\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    exp_emb = E_exp(dummy_input)\n",
    "    id_emb = E_id(dummy_input)\n",
    "    \n",
    "    print(f\"Expression embedding shape: {exp_emb.shape}\")\n",
    "    print(f\"Identity embedding shape: {id_emb.shape}\")\n",
    "    \n",
    "    # Statistics network\n",
    "    mi_score = stat_net(exp_emb, id_emb)\n",
    "    print(f\"MI score shape: {mi_score.shape}\")\n",
    "    \n",
    "    # Discriminator\n",
    "    disc_score = disc(exp_emb, id_emb)\n",
    "    print(f\"Discriminator score shape: {disc_score.shape}\")\n",
    "    \n",
    "    # Classifier\n",
    "    pred = clf(exp_emb)\n",
    "    print(f\"Classification output shape: {pred.shape}\")\n",
    "    \n",
    "    print(\"\\nModel summary:\")\n",
    "    print(f\"Expression Encoder parameters: {sum(p.numel() for p in E_exp.parameters())}\")\n",
    "    print(f\"Identity Encoder parameters: {sum(p.numel() for p in E_id.parameters())}\")\n",
    "    print(f\"Statistics Network parameters: {sum(p.numel() for p in stat_net.parameters())}\")\n",
    "    print(f\"Discriminator parameters: {sum(p.numel() for p in disc.parameters())}\")\n",
    "    print(f\"Classifier parameters: {sum(p.numel() for p in clf.parameters())}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run demo first\n",
    "    demo_model()\n",
    "    \n",
    "    # Then run training (uncomment the line below when you have the dataset)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9772533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load test dataset\n",
    "    try:\n",
    "        test_dataset = TestFERDataset(\"/test\")\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        print(f\"Test dataset loaded: {len(test_dataset)} images\")\n",
    "    except:\n",
    "        print(\"Test dataset not found. Please ensure 'test' directory exists with proper structure.\")\n",
    "        return\n",
    "    \n",
    "    # Load trained models\n",
    "    try:\n",
    "        E_exp = Encoder().to(device)\n",
    "        clf = ExpressionClassifier().to(device)\n",
    "        \n",
    "        # Load latest saved weights\n",
    "        E_exp.load_state_dict(torch.load('expression_encoder_epoch_9.pth'))\n",
    "        clf.load_state_dict(torch.load('classifier_epoch_9.pth'))\n",
    "        \n",
    "        print(\"Models loaded successfully\")\n",
    "    except:\n",
    "        print(\"Model weights not found. Please train the model first.\")\n",
    "        return\n",
    "    \n",
    "    # Set models to evaluation mode\n",
    "    E_exp.eval()\n",
    "    clf.eval()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Starting testing...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Convert grayscale to RGB if needed\n",
    "            if images.shape[1] == 1:\n",
    "                images = images.repeat(1, 3, 1, 1)\n",
    "            \n",
    "            # Forward pass\n",
    "            expression_embeddings = E_exp(images)\n",
    "            predictions = clf(expression_embeddings)\n",
    "            \n",
    "            # Get predicted classes\n",
    "            predicted_classes = torch.argmax(predictions, dim=1)\n",
    "            \n",
    "            # Store results\n",
    "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            if batch_idx % 40 == 0:\n",
    "                print(f\"Processed batch {batch_idx}/{len(test_loader)}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    # Class names\n",
    "    class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    print(f\"\\n=== TEST RESULTS ===\")\n",
    "    print(f\"Total test samples: {len(all_labels)}\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(f\"\\n=== CLASSIFICATION REPORT ===\")\n",
    "    print(classification_report(all_labels, all_predictions, target_names=class_names))\n",
    "\n",
    "def demo_model():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create models\n",
    "    E_exp = Encoder().to(device)\n",
    "    E_id = Encoder().to(device)\n",
    "    stat_net = StatisticsNetwork(64).to(device)\n",
    "    disc = Discriminator(64).to(device)\n",
    "    clf = ExpressionClassifier().to(device)\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = torch.randn(4, 3, 112, 112).to(device)\n",
    "    \n",
    "    print(\"Model Architecture Demo:\")\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    exp_emb = E_exp(dummy_input)\n",
    "    id_emb = E_id(dummy_input)\n",
    "    \n",
    "    print(f\"Expression embedding shape: {exp_emb.shape}\")\n",
    "    print(f\"Identity embedding shape: {id_emb.shape}\")\n",
    "    \n",
    "    # Statistics network\n",
    "    mi_score = stat_net(exp_emb, id_emb)\n",
    "    print(f\"MI score shape: {mi_score.shape}\")\n",
    "    \n",
    "    # Discriminator\n",
    "    disc_score = disc(exp_emb, id_emb)\n",
    "    print(f\"Discriminator score shape: {disc_score.shape}\")\n",
    "    \n",
    "    # Classifier\n",
    "    pred = clf(exp_emb)\n",
    "    print(f\"Classification output shape: {pred.shape}\")\n",
    "    \n",
    "    print(\"\\nModel summary:\")\n",
    "    print(f\"Expression Encoder parameters: {sum(p.numel() for p in E_exp.parameters())}\")\n",
    "    print(f\"Identity Encoder parameters: {sum(p.numel() for p in E_id.parameters())}\")\n",
    "    print(f\"Statistics Network parameters: {sum(p.numel() for p in stat_net.parameters())}\")\n",
    "    print(f\"Discriminator parameters: {sum(p.numel() for p in disc.parameters())}\")\n",
    "    print(f\"Classifier parameters: {sum(p.numel() for p in clf.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63915a55-a601-4195-b022-5349a3b8ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a0294-a9fe-4e4a-bbc1-a82b659d5c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-cuda-env)",
   "language": "python",
   "name": "torch-cuda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
